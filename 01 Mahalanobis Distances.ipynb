{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "from scipy import stats\n",
    "from scipy.spatial import distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to compute Mahalanobis Distance in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carat</th>\n",
       "      <th>depth</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.23</td>\n",
       "      <td>61.5</td>\n",
       "      <td>326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.21</td>\n",
       "      <td>59.8</td>\n",
       "      <td>326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.23</td>\n",
       "      <td>56.9</td>\n",
       "      <td>327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.29</td>\n",
       "      <td>62.4</td>\n",
       "      <td>334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.31</td>\n",
       "      <td>63.3</td>\n",
       "      <td>335</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   carat  depth  price\n",
       "0   0.23   61.5    326\n",
       "1   0.21   59.8    326\n",
       "2   0.23   56.9    327\n",
       "3   0.29   62.4    334\n",
       "4   0.31   63.3    335"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('diamonds.csv').iloc[:, [0,4,6]]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to calculate Mahalanobis Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carat</th>\n",
       "      <th>depth</th>\n",
       "      <th>price</th>\n",
       "      <th>mahala</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.23</td>\n",
       "      <td>61.5</td>\n",
       "      <td>326</td>\n",
       "      <td>5.239696e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.21</td>\n",
       "      <td>59.8</td>\n",
       "      <td>326</td>\n",
       "      <td>5.239896e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.23</td>\n",
       "      <td>56.9</td>\n",
       "      <td>327</td>\n",
       "      <td>5.239813e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.29</td>\n",
       "      <td>62.4</td>\n",
       "      <td>334</td>\n",
       "      <td>5.239210e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.31</td>\n",
       "      <td>63.3</td>\n",
       "      <td>335</td>\n",
       "      <td>5.239031e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   carat  depth  price        mahala\n",
       "0   0.23   61.5    326  5.239696e+07\n",
       "1   0.21   59.8    326  5.239896e+07\n",
       "2   0.23   56.9    327  5.239813e+07\n",
       "3   0.29   62.4    334  5.239210e+07\n",
       "4   0.31   63.3    335  5.239031e+07"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mahalanobis(x=None, data=None, cov=None):\n",
    "    \"\"\"Compute the Mahalanobis Distance between each row of x and the data  \n",
    "    x    : vector or matrix of data with, say, p columns.\n",
    "    data : ndarray of the distribution from which Mahalanobis distance of each observation of x is to be computed.\n",
    "    cov  : covariance matrix (p x p) of the distribution. If None, will be computed from data.\n",
    "    \"\"\"\n",
    "    x_minus_mu = x - np.mean(data)\n",
    "    if not cov:\n",
    "        cov = np.cov(data.values.T)\n",
    "    inv_covmat = sp.linalg.inv(cov)\n",
    "    left_term = np.dot(x_minus_mu, inv_covmat)\n",
    "    mahal = np.dot(left_term, x_minus_mu.T)\n",
    "    return mahal.diagonal()\n",
    "\n",
    "df_x = df[['carat', 'depth', 'price']].head(500)\n",
    "df_x['mahala'] = mahalanobis(x=df_x, data=df[['carat', 'depth', 'price']])\n",
    "df_x.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Usecase 1: Multivariate outlier detection using Mahalanobis distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.21034037197618"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Critical values for two degrees of freedom\n",
    "from scipy.stats import chi2\n",
    "chi2.ppf((1-0.01), df=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That mean an observation can be considered as extreme if its Mahalanobis distance exceeds 9.21. If you prefer P values instead to determine if an observation is extreme or not, the P values can be computed as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carat</th>\n",
       "      <th>depth</th>\n",
       "      <th>price</th>\n",
       "      <th>mahala</th>\n",
       "      <th>p_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.23</td>\n",
       "      <td>61.5</td>\n",
       "      <td>326</td>\n",
       "      <td>5.239696e+07</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.21</td>\n",
       "      <td>59.8</td>\n",
       "      <td>326</td>\n",
       "      <td>5.239896e+07</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.23</td>\n",
       "      <td>56.9</td>\n",
       "      <td>327</td>\n",
       "      <td>5.239813e+07</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.29</td>\n",
       "      <td>62.4</td>\n",
       "      <td>334</td>\n",
       "      <td>5.239210e+07</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.31</td>\n",
       "      <td>63.3</td>\n",
       "      <td>335</td>\n",
       "      <td>5.239031e+07</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.24</td>\n",
       "      <td>62.8</td>\n",
       "      <td>336</td>\n",
       "      <td>5.239594e+07</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.24</td>\n",
       "      <td>62.3</td>\n",
       "      <td>336</td>\n",
       "      <td>5.239606e+07</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.26</td>\n",
       "      <td>61.9</td>\n",
       "      <td>337</td>\n",
       "      <td>5.239460e+07</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.22</td>\n",
       "      <td>65.1</td>\n",
       "      <td>337</td>\n",
       "      <td>5.239695e+07</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.23</td>\n",
       "      <td>59.4</td>\n",
       "      <td>338</td>\n",
       "      <td>5.239759e+07</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   carat  depth  price        mahala  p_value\n",
       "0   0.23   61.5    326  5.239696e+07      0.0\n",
       "1   0.21   59.8    326  5.239896e+07      0.0\n",
       "2   0.23   56.9    327  5.239813e+07      0.0\n",
       "3   0.29   62.4    334  5.239210e+07      0.0\n",
       "4   0.31   63.3    335  5.239031e+07      0.0\n",
       "5   0.24   62.8    336  5.239594e+07      0.0\n",
       "6   0.24   62.3    336  5.239606e+07      0.0\n",
       "7   0.26   61.9    337  5.239460e+07      0.0\n",
       "8   0.22   65.1    337  5.239695e+07      0.0\n",
       "9   0.23   59.4    338  5.239759e+07      0.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute the P-Values\n",
    "df_x['p_value'] = 1 - chi2.cdf(df_x['mahala'], 2)\n",
    "\n",
    "# Extreme values with a significance level of 0.01\n",
    "df_x.loc[df_x.p_value < 0.01].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you compare the above observations against rest of the dataset, they are clearly extreme."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Usecase 2: Mahalanobis Distance for Classification Problems\n",
    "Mahalanobis distance can be used for classification problems. A naive implementation of a Mahalanobis classifier is coded below. The intuition is that, an observation is assigned the class that it is closest to based on the Mahalanobis distance. Let’s see an example implementation on the BreastCancer dataset, where the objective is to determine if a tumour is benign or malignant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cl.thickness</th>\n",
       "      <th>Cell.size</th>\n",
       "      <th>Marg.adhesion</th>\n",
       "      <th>Epith.c.size</th>\n",
       "      <th>Bare.nuclei</th>\n",
       "      <th>Bl.cromatin</th>\n",
       "      <th>Normal.nucleoli</th>\n",
       "      <th>Mitoses</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Cl.thickness  Cell.size  Marg.adhesion  Epith.c.size  Bare.nuclei  \\\n",
       "0             5          1              1             2          1.0   \n",
       "1             5          4              5             7         10.0   \n",
       "2             3          1              1             2          2.0   \n",
       "3             6          8              1             3          4.0   \n",
       "4             4          1              3             2          1.0   \n",
       "\n",
       "   Bl.cromatin  Normal.nucleoli  Mitoses  Class  \n",
       "0            3                1        1      0  \n",
       "1            3                2        1      0  \n",
       "2            3                1        1      0  \n",
       "3            3                7        1      0  \n",
       "4            3                1        1      0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.read_csv('BreastCancer.csv', usecols=['Cl.thickness', 'Cell.size', 'Marg.adhesion', 'Epith.c.size', 'Bare.nuclei', 'Bl.cromatin', 'Normal.nucleoli', 'Mitoses', 'Class'])\n",
    "df2.dropna(inplace=True)  # drop missing values.\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s split the dataset in 70:30 ratio as Train and Test. And the training dataset is split into homogeneous groups of ‘pos'(1) and ‘neg'(0) classes. To predict the class of the test dataset, we measure the Mahalanobis distances between a given observation (row) and both the positive (xtrain_pos) and negative datasets(xtrain_neg). Then that observation is assigned the class based on the group it is closest to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Cl.thickness', 'Cell.size', 'Marg.adhesion', 'Epith.c.size',\n",
       "       'Bare.nuclei', 'Bl.cromatin', 'Normal.nucleoli', 'Mitoses', 'Class'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(df2.drop('Class', axis=1), df2['Class'], test_size=.3, random_state=100)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(x, y, test_size=0.3, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the training data as pos and neg\n",
    "xtrain_pos = xtrain.loc[ytrain == 1, :]\n",
    "xtrain_neg = xtrain.loc[ytrain == 0, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s build the MahalanobiBinaryClassifier. To do that, you need to define the predict_proba() and the predict() methods. This classifier does not require a separate fit() (training) method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   pred  true\n",
      "0     1     0\n",
      "1     1     1\n",
      "2     0     0\n",
      "3     1     0\n",
      "4     0     0\n"
     ]
    }
   ],
   "source": [
    "class MahalanobisBinaryClassifier():\n",
    "    def __init__(self, xtrain, ytrain):\n",
    "        self.xtrain_pos = xtrain.loc[ytrain == 1, :]\n",
    "        self.xtrain_neg = xtrain.loc[ytrain == 0, :]\n",
    "\n",
    "    def predict_proba(self, xtest):\n",
    "        pos_neg_dists = [(p,n) for p, n in zip(mahalanobis(xtest, self.xtrain_pos), mahalanobis(xtest, self.xtrain_neg))]\n",
    "        return np.array([(1-n/(p+n), 1-p/(p+n)) for p,n in pos_neg_dists])\n",
    "\n",
    "    def predict(self, xtest):\n",
    "        return np.array([np.argmax(row) for row in self.predict_proba(xtest)])\n",
    "\n",
    "\n",
    "clf = MahalanobisBinaryClassifier(xtrain, ytrain)        \n",
    "pred_probs = clf.predict_proba(xtest)\n",
    "pred_class = clf.predict(xtest)\n",
    "\n",
    "# Pred and Truth\n",
    "pred_actuals = pd.DataFrame([(pred, act) for pred, act in zip(pred_class, ytest)], columns=['pred', 'true'])\n",
    "print(pred_actuals[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s see how the classifier performed on the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUROC:  0.9867692307692308\n",
      "\n",
      "Confusion Matrix: \n",
      " [[96 34]\n",
      " [ 0 75]]\n",
      "\n",
      "Accuracy Score:  0.8341463414634146\n",
      "\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.74      0.85       130\n",
      "           1       0.69      1.00      0.82        75\n",
      "\n",
      "    accuracy                           0.83       205\n",
      "   macro avg       0.84      0.87      0.83       205\n",
      "weighted avg       0.89      0.83      0.84       205\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score, roc_auc_score, confusion_matrix\n",
    "truth = pred_actuals.loc[:, 'true']\n",
    "pred = pred_actuals.loc[:, 'pred']\n",
    "scores = np.array(pred_probs)[:, 1]\n",
    "print('AUROC: ', roc_auc_score(truth, scores))\n",
    "print('\\nConfusion Matrix: \\n', confusion_matrix(truth, pred))\n",
    "print('\\nAccuracy Score: ', accuracy_score(truth, pred))\n",
    "print('\\nClassification Report: \\n', classification_report(truth, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Usecase 3: One-Class Classification\n",
    "One Class classification is a type of algorithm where the training dataset contains observations belonging to only one class.\n",
    "\n",
    "With only that information known, the objective is to figure out if a given observation in a new (or test) dataset belongs to that class. You might wonder when would such a situation occur.\n",
    "\n",
    "One Class classification is a type of algorithm where the training dataset contains observations belonging to only one class.\n",
    "\n",
    "With only that information known, the objective is to figure out if a given observation in a new (or test) dataset belongs to that class. You might wonder when would such a situation occur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('BreastCancer.csv', usecols=['Cl.thickness', 'Cell.size', 'Marg.adhesion', 'Epith.c.size', 'Bare.nuclei', 'Bl.cromatin', 'Normal.nucleoli', 'Mitoses', 'Class'])\n",
    "df.dropna(inplace=True)  # drop missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting 50% of the dataset into training and test. Only the 1’s are retained in the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(df.drop('Class', axis=1), df['Class'], test_size=.5, random_state=100)\n",
    "\n",
    "# Split the training data as pos and neg\n",
    "xtrain_pos = xtrain.loc[ytrain == 1, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s build the MahalanobisOneClassClassifier and get the mahalanobis distance of each datapoint in x from the training set (xtrain_pos):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Critical value is:  14.067140449340167\n",
      "       mahal  true_class\n",
      "0  11.306536           0\n",
      "1  12.824249           1\n",
      "2  11.654914           0\n",
      "3  11.298144           0\n",
      "4  12.716892           0\n"
     ]
    }
   ],
   "source": [
    "class MahalanobisOneclassClassifier():\n",
    "    def __init__(self, xtrain, significance_level=0.01):\n",
    "        self.xtrain = xtrain\n",
    "        self.critical_value = chi2.ppf((1-significance_level), df=xtrain.shape[1]-1)\n",
    "        print('Critical value is: ', self.critical_value)\n",
    "\n",
    "    def predict_proba(self, xtest):\n",
    "        mahalanobis_dist = mahalanobis(xtest, self.xtrain)\n",
    "        self.pvalues = 1 - chi2.cdf(mahalanobis_dist, 2)\n",
    "        return mahalanobis_dist\n",
    "\n",
    "    def predict(self, xtest):\n",
    "        return np.array([int(i) for i in self.predict_proba(xtest) > self.critical_value])\n",
    "\n",
    "clf = MahalanobisOneclassClassifier(xtrain_pos, significance_level=0.05)\n",
    "mahalanobis_dist = clf.predict_proba(xtest)\n",
    "\n",
    "# Pred and Truth\n",
    "mdist_actuals = pd.DataFrame([(m, act) for m, act in zip(mahalanobis_dist, ytest)], columns=['mahal', 'true_class'])\n",
    "print(mdist_actuals[:5]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have the Mahalanobis distance and the actual class of each observation. I would expect those observations with low Mahalanobis distance to be 1’s. So, I sort the mdist_actuals by Mahalanobis distance and quantile cut the rows into 10 equal sized groups. The observations in the top quantiles should have more 1’s compared to the ones in the bottom. Let’s see"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          avg_mahaldist  sum_of_trueclass\n",
      "quantile                                 \n",
      "1              6.191630                32\n",
      "2              9.191590                28\n",
      "3             10.790403                19\n",
      "4             11.609966                10\n",
      "5             12.434227                 5\n",
      "6             13.181877                11\n",
      "7             14.044480                 1\n",
      "8             15.305396                 7\n",
      "9             16.810820                 2\n",
      "10            19.149191                15\n"
     ]
    }
   ],
   "source": [
    "# quantile cut in 10 pieces\n",
    "mdist_actuals['quantile'] = pd.qcut(mdist_actuals['mahal'], \n",
    "                                    q=[0, .10, .20, .3, .4, .5, .6, .7, .8, .9, 1], \n",
    "                                    labels=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "\n",
    "# sort by mahalanobis distance\n",
    "mdist_actuals.sort_values('mahal', inplace=True)\n",
    "perc_truths = mdist_actuals.groupby('quantile').agg({'mahal': np.mean, 'true_class': np.sum}).rename(columns={'mahal':'avg_mahaldist', 'true_class':'sum_of_trueclass'})\n",
    "print(perc_truths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you notice above, nearly 90% of the 1’s (malignant cases) fall within the first 40%ile of the Mahalanobis distance.\n",
    "\n",
    "Incidentally, all of these are lower than the critical value pf 14.05. So, let’s the critical value as the cutoff and mark those observations with Mahalanobis distance less than the cutoff as positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix: \n",
      " [[ 87 125]\n",
      " [ 25 105]]\n",
      "\n",
      "Accuracy Score:  0.5614035087719298\n",
      "\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.41      0.54       212\n",
      "           1       0.46      0.81      0.58       130\n",
      "\n",
      "    accuracy                           0.56       342\n",
      "   macro avg       0.62      0.61      0.56       342\n",
      "weighted avg       0.66      0.56      0.55       342\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score, roc_auc_score, confusion_matrix\n",
    "\n",
    "# Positive if mahalanobis \n",
    "pred_actuals = pd.DataFrame([(int(p), y) for y, p in zip(ytest, clf.predict_proba(xtest) < clf.critical_value)], columns=['pred', 'true'])\n",
    "\n",
    "# Accuracy Metrics\n",
    "truth = pred_actuals.loc[:, 'true']\n",
    "pred = pred_actuals.loc[:, 'pred']\n",
    "print('\\nConfusion Matrix: \\n', confusion_matrix(truth, pred))\n",
    "print('\\nAccuracy Score: ', accuracy_score(truth, pred))\n",
    "print('\\nClassification Report: \\n', classification_report(truth, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, without the knowledge of the benign class, we are able to accurately predict the class of 87% of the observations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this post, we covered nearly everything about Mahalanobis distance: the intuition behind the formula, the actual calculation in python and how it can be used for multivariate anomaly detection, binary classification, and one-class classification. It is known to perform really well when you have a highly imbalanced dataset. Hope it was useful? Please leave your comments below and I will see you in the next one.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
